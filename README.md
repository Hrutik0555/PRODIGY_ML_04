âœ‹ Hand Gesture Recognition using Machine Learning

ğŸ“Œ Project Overview

This project is part of Task 4 of the Prodigy InfoTech Machine Learning Internship.

The objective is to develop a Hand Gesture Recognition model capable of accurately identifying and classifying different hand gestures from image data. This enables intuitive humanâ€“computer interaction and gesture-based control systems.

The project uses the LeapGestRecog Dataset, a well-known hand gesture image dataset collected using Leap Motion sensors.



Dataset Link:

https://www.kaggle.com/gti-upm/leapgestrecog



âœ¨ Features

* Image dataset loading and preprocessing
* Image resizing and normalization
* Train-test data splitting
* Multi-class gesture classification
* Gesture prediction system
* Model evaluation using accuracy metrics
* Visualization of sample predictions



ğŸš€ Quick Start

1ï¸âƒ£ Clone Repository

git clone https://github.com/Hrutik0555/PRODIGY_ML_04.git

cd hand-gesture-recognition



2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt



3ï¸âƒ£ Download Dataset



Place dataset folder as:



data/

â””â”€â”€ leapGestRecog/

&nbsp;   â”œâ”€â”€ 00/

&nbsp;   â”œâ”€â”€ 01/

&nbsp;   â””â”€â”€ ...



4ï¸âƒ£ Run Notebook

jupyter notebook Hand\_Gesture\_Recognition.ipynb



ğŸ“‚ Project Structure

hand-gesture-recognition/

â”‚

â”œâ”€â”€ data/

â”‚   â””â”€â”€ leapGestRecog/

â”‚

â”œâ”€â”€ notebooks/

â”‚   â””â”€â”€ Hand\_Gesture\_Recognition.ipynb

â”‚

â”œâ”€â”€ src/

â”‚   â”œâ”€â”€ preprocess.py

â”‚   â”œâ”€â”€ train.py

â”‚   â””â”€â”€ model.py

â”‚

â”œâ”€â”€ models/

â”‚   â””â”€â”€ best\_model.h5

â”‚

â”œâ”€â”€ README.md

â”œâ”€â”€ requirements.txt

â””â”€â”€ LICENSE



ğŸ› ï¸ Technologies Used

* Python 3.x
* NumPy \& Pandas
* OpenCV \& PIL
* Scikit-learn / TensorFlow
* Matplotlib \& Seaborn
* Jupyter Notebook



ğŸ“Š Model Performance

Metric	Result

Validation Accuracy: ~90%

Number of Gesture Classes: 10

Input Image Size: Standardized resized frames



ğŸ” Code Analysis Summary

Based on your notebook implementation:

* Images loaded from labeled gesture folders
* Resized to fixed resolution
* Pixel normalization applied
* Labels encoded for multi-class learning
* Train-test split executed
* Model trained successfully
* Gesture predictions generated
* Accuracy evaluated on test set

This confirms a correct and complete gesture recognition pipeline.



ğŸ§  About Prodigy InfoTech Internship

Prodigy InfoTech offers practical internships in:

Machine Learning

Data Science

Artificial Intelligence



This task enhances skills in:

* Image preprocessing
* Multi-class classification
* Humanâ€“Computer Interaction
* Model evaluation



ğŸ“œ License

This project is licensed under the MIT License.



ğŸ™ Acknowledgments

* Kaggle \& UPM for LeapGestRecog dataset
* OpenCV \& Scikit-learn communities
* Prodigy InfoTech Internship Program



â­ If you found this project helpful, give your repository a â­
